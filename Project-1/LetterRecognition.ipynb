{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1369bcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.1\n",
    "\n",
    "!git clone https://github.com/sorki/python-mnist\n",
    "!./python-mnist/get-data.sh\n",
    "!pip3 install emnist\n",
    "from emnist import extract_training_samples\n",
    "\n",
    "print(\"Imported the EMNIST libraries we need!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef4b51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.2\n",
    "\n",
    "# Grab the data from the OpenML website\n",
    "# X will be our images and Y will be the lables\n",
    "X, Y = extract_training_samples('letters')\n",
    "\n",
    "# Make sure that every pixel in all of the images is a value between 0 and 1\n",
    "X = X / 255.\n",
    "\n",
    "# Use the first 60000 instances as training and the next 10000 as testing\n",
    "X_train, X_test = X[:60000], X[60000:70000]\n",
    "Y_train, Y_test = Y[:60000], Y[60000:70000]\n",
    "\n",
    "# There is one other thing we need to do, we need to record the number of samples in each dataset and the number of pixels in each image\n",
    "# Flatten the 28x28 images into 784-element vectors\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "\n",
    "print(\"Extracted our samples and divided our training and testing data sets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbb5626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.3\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_index = 8888 # <<<<<< You can update this value to look at other images\n",
    "img = X_train[img_index]\n",
    "print(\"Image Label: \" + str(chr(Y_train[img_index]+96)))\n",
    "plt.imshow(img.reshape((28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111ff3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2.1\n",
    "\n",
    "# Install the libraries we need\n",
    "!pip3 install scikit-learn\n",
    "\n",
    "# These two lines import the ML libraries we need\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# This created our first MLP with 1 hidden layer eith 50 neurons and sets it to run through the data 20 times\n",
    "mlpl = MLPClassifier(hidden_layer_sizes=(50,), max_iter=20, alpha=le-4, solver='sgd', verbose=10, tol=le-4, random_state=1, learning_rate_init=.1)\n",
    "\n",
    "print(\"Created our first MLP network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b10ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3.1\n",
    "\n",
    "mlpl.fit(X_train, Y_train)\n",
    "print(\"Training set score: %f\" % mlpl.score(X_train, Y_train))\n",
    "print(\"Test set score: %f\" % mlpl.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b763575d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3.2\n",
    "\n",
    "# First let's initialize a list with all the predicted values from the training set\n",
    "Y_pred = mlpl.predict(X_test)\n",
    "\n",
    "# Now let's visualize the errors between the predictions and the actual lables using a confustion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "plt.matshow(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81d495c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3.3\n",
    "\n",
    "# You can change this to any letters that you think the neural network may have confused...\n",
    "predicted_letter = 'l'\n",
    "actual_letter = 'i'\n",
    "\n",
    "# This code counts all the mistakes for the letters above\n",
    "mistake_list = []\n",
    "for i in range(len(Y_test)):\n",
    "    if (Y_test[i] == (ord(actual_letter) - 96) and Y_pred[i] == (ord(predicted_letter) - 96)):\n",
    "        mistake_list.append(i)\n",
    "print(\"There were \" + str(len(mistake_list)) + \" times that the letter \" + actual_letter + \"was predicted to be the letter \" + predicted_letter + \".\")\n",
    "\n",
    "# Once we know how many mistakes were made, we can change this to see an image of particular one\n",
    "mistake_to_show = 4 # <<<<<< e.g., change this to 3 if you want to see the 4th mistake\n",
    "\n",
    "# This code checks that the number mistake you asked for can be shown and if so, displays an image of it\n",
    "if (len(mistake_list) > mistake_to_show):\n",
    "    img = X_test[mistake_list[mistake_to_show]]\n",
    "    plt.imshow(img.reshape((28,28)))\n",
    "else:\n",
    "    print(\"Couldn't show mistake number \" + str(mistake_to_show) + \" because there were only \" + str(len(mistake_list)) + \" mistakes to show!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898b5295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3.4\n",
    "\n",
    "# Change some of the values in the below statement and re-run to see how thay affect performance!\n",
    "mlp2 = MLPClassifier(hidden_layer_sizes=(100, 100, 100, 100, 100, ), max_iter=50, alpha=le-4, learning_rate_init=.1)\n",
    "mlp2.fit(X_train, Y_train)\n",
    "print(\"Training set score: %f\" % mlp2.score(X_train, Y_train))\n",
    "print(\"Test set score: %f\" % mlp2.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da60c344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4.1\n",
    "\n",
    "# Pulls the scanned data set from GitHub\n",
    "!git clone https://github.com/crash-course-ai/lab1-neural-networks.git\n",
    "!git pull\n",
    "!ls lab1-neural-networks/letters_mod\n",
    "!cd /content.lab1-neural-networks/letters_mod\n",
    "!pwd\n",
    "\n",
    "# Puts all the data in the \"files\" variable\n",
    "import os\n",
    "path, dirs, files = next(os.walk(\"/content/lab1-neural-networks/letters_mod\"))\n",
    "files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90c259b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4.2\n",
    "\n",
    "# These libraries let us import letters, resize them, and print them out\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This code processes all the scanned images and adds them to the handwritten_story\n",
    "handwritten_story = []\n",
    "for i in range(len(files)):\n",
    "    img = cv2.imread(\"/content.lab1-neural-networks/letters_mod\"+files[i], cv2.IMREAD_GRAYSCALE)\n",
    "    handwritten_story.append(img)\n",
    "\n",
    "print(\"Imported the scanned images.\")\n",
    "\n",
    "plt.imshow(handwritten_story[4]) # <----- Chnage this index to see different letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54af18f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4.3\n",
    "\n",
    "# These are libraries we need to do some math on the image to be able to give it to the MLP in the right format and to resize it to 28x28 pixels\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "typed_story = \" \"\n",
    "for letter in handwritten_story:\n",
    "    letter = cv2.resize(letter, (28, 28), interpolation=cv2.INTER_CUBIC)\n",
    "    single_item_array = (numpy.array(letter)).reshape(1, 784)\n",
    "    predection = mlp2.predict(single_item_array)\n",
    "    typed_story = typed_story + str(chr(predection[0] + 96))\n",
    "\n",
    "print(\"Conversion to typed story complete!\")\n",
    "print(typed_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded829de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4.4\n",
    "\n",
    "# This is a library we need to do some math on the image to be able to give it to the MLP in the right format\n",
    "import numpy\n",
    "\n",
    "typed_story = \" \"\n",
    "for letter in handwritten_story:\n",
    "    letter = cv2.resize(letter, (28, 28), inpterpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "    # This bit of code checks to see if the image is just a blank space by looking at the color of all pixels summed\n",
    "    total_pixel_vlaue = 0\n",
    "    for j in range(28):\n",
    "        for k in range(28):\n",
    "            total_pixel_vlaue += letter[j,k]\n",
    "    if total_pixel_vlaue < 20:\n",
    "        typed_story = typed_story + \" \"\n",
    "    else: # Is it is NOT a blank, it actually runs the prediction algorithm on it\n",
    "        single_item_array = (numpy.array(letter)).reshape(1, 784)\n",
    "        predection = mlp2.predict(single_item_array)\n",
    "        typed_story = typed_story + str(chr(predection[0] + 96))\n",
    "\n",
    "print(\"Conversion to typed story complete!\")\n",
    "print(typed_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5975592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4.5\n",
    "\n",
    "# These steps process the scanned images to be in the same format and have the same properties as the EMMIST inmages\n",
    "# They are described by the ENNIST authors in detail here: https://arxiv.org/abs/1702.05373v1\n",
    "processed_story = []\n",
    "\n",
    "for img in handwritten_story:\n",
    "    # step 1: Apply Gaussian blur filter\n",
    "    img =  cv2.GaussianBlur(img, (7,7), 0)\n",
    "    # steps 2 and 3: Extract the Region of Interest in the image and center in square\n",
    "    points = cv2.findNonzero(img)\n",
    "    x, y, w, h = cv2.boundingRect(points)\n",
    "    if (w > 0 and h > 0):\n",
    "        if w > h:\n",
    "            y = y - (w-h)//2\n",
    "            img = img[y:y+w, x:x+w]\n",
    "        else:\n",
    "            x = x - (h-w)//2\n",
    "            img = img[y:y+h, x:x+h]\n",
    "    \n",
    "    #step 4: Resize and resample to be 28 x 28 pixels\n",
    "    img = cv2.resize(img, (28,28), interpolation = cv2.INTER_CUBIC)\n",
    "    \n",
    "    #step 5: Normalize pixels and reshape before adding to the new story array\n",
    "    img = img/255\n",
    "    img = img.reshape((28,28))\n",
    "    processed_story.append(img)\n",
    "    \n",
    "print(\"Processed the scanned images.\")\n",
    "\n",
    "import matplotlib.pyplot as pit\n",
    "pit.imshow(processed_story[4]) # <<<<< Change this index if you want to see a different letter from the story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b698801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4.6\n",
    "\n",
    "# This is a library we need to do some math on the image to be able to give it to the MLP in the right format \n",
    "import numpy\n",
    "\n",
    "typed_story = \" \"\n",
    "for letter in processed_story:\n",
    "    # This bit of code checks to see if the image is just a blank space by looking at the color of all the pixels summed\n",
    "    total_pixel_value = 0\n",
    "    for j in range(28):\n",
    "        for k in range(28):\n",
    "            total_pixel_value += letter[j,k]\n",
    "        if total_pixel_value < 20:\n",
    "            typed_story = typed_story + \" \"\n",
    "        else: # If it NOT a blank, it actually runs the prediction algorithm on it\n",
    "            single_item_array = (numpy.array(letter)).reshape (1, 784)\n",
    "            prediction = mlp2.predict(single_item_array)\n",
    "            typed_story = typed_story + str(chr(prediction[0]+ 96))\n",
    "\n",
    "print(\"Conversion to typed story complete!\")\n",
    "print(typed_story)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
